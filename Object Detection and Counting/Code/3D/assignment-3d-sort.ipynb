{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sort' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "!git clone https://github.com/abewley/sort.git\n",
    "from sort.sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gandalf/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-3-22 Python-3.8.10 torch-1.13.0+cu117 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_tracker = Sort()\n",
    "bounding_boxes_ids = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the video file for reading\n",
    "vidcap = cv2.VideoCapture('./video1.mp4')\n",
    "\n",
    "# Initializing variables for processing frames\n",
    "success = True\n",
    "count2 = 0\n",
    "img_array = []\n",
    "track_ids = []\n",
    "count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through each image of the video file\n",
    "while success:\n",
    "    # Reading the next image from the video file\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "    # Checking if the image was successfully read\n",
    "    if(success == 0 or image is None): \n",
    "        break\n",
    "\n",
    "    # Perform object detection on the image\n",
    "    pred = model(image)\n",
    "    car_pred = pred.pred[0][pred.pred[0][:, 5] == 2]\n",
    "    boxes = car_pred[:, :4].cpu().numpy()\n",
    "    confidences = car_pred[:, 4].cpu().numpy()\n",
    "    class_label = car_pred[:, 5].cpu().numpy()\n",
    "\n",
    "    # Filter out low-confidence detections and track objects using an object tracker\n",
    "    if bounding_boxes := [\n",
    "        boxes[i] for i in range(len(class_label)) if (confidences[i] > 0.5)\n",
    "    ]:\n",
    "        bounding_boxes = np.array(bounding_boxes)\n",
    "        tracks = object_tracker.update(bounding_boxes)\n",
    "\n",
    "        # Update the list of bounding box IDs\n",
    "        for i in range(tracks.shape[0]):\n",
    "            bounding_boxes_ids = np.append(bounding_boxes_ids, np.array([tracks[i][4]]))\n",
    "\n",
    "        # Count the number of unique bounding box IDs to get the car count for the frame\n",
    "        count = np.unique(bounding_boxes_ids).shape[0]\n",
    "\n",
    "        # Draw bounding boxes and labels around each car\n",
    "        for i in range(bounding_boxes.shape[0]):\n",
    "            cv2.rectangle(image, (int(bounding_boxes[i][0]), int(bounding_boxes[i][1])), (int(bounding_boxes[i][2]), int(bounding_boxes[i][3])), (0, 255, 0), 3)\n",
    "            cv2.putText(image, \"Car\", (int(bounding_boxes[i][0])-10, int(bounding_boxes[i][1])-10),  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the car count on the image\n",
    "    cv2.putText(image, f'Number of Cars: {int(count)}', (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (255,255,255), 3)\n",
    "\n",
    "    # Add the current frame to an array of frames\n",
    "    img_array.append(image)\n",
    "\n",
    "    # If the current frame is one of the specified frames, save it as a JPEG file\n",
    "    if(count2 == 12 or count2 == 490 or count2 == 200 or count2 == 400):\n",
    "        cv2.imwrite(\"frame%d.jpg\" % count2, img_array[-1])     # save frame as JPEG file\n",
    "\n",
    "    # Increment the frame counter\n",
    "    count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the size of the frames and initializing a VideoWriter object for writing the output video file\n",
    "height, width, layers = img_array[0].shape\n",
    "size = (width,height)\n",
    "out = cv2.VideoWriter('project_YOLO.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "# Writing each frame of the output video file\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "    \n",
    "# Releasing the VideoWriter object\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
